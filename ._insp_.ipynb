{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory is already set to the package directory\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Jul 10 10:00:25 2024\n",
    "\n",
    "@author: sdd380\n",
    "\"\"\"\n",
    "import os\n",
    "# Print the current working directory\n",
    "cwd = os.getcwd()\n",
    "if cwd.endswith('SOM_package'):\n",
    "    print('Current working directory is already set to the package directory')\n",
    "else:\n",
    "    os.chdir('../')\n",
    "    os.chdir(cwd + '/SOM_package')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from som_data_struct import som_data_struct\n",
    "from som_normalize import som_normalize\n",
    "from som_make import som_make\n",
    "from som_bmus import som_bmus\n",
    "from som_ind2sub import som_ind2sub\n",
    "from som_denormalize import som_denormalize\n",
    "from reader import *\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import copy\n",
    "from sklearn.cluster import KMeans\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -19.43835449, -919.3968239 ,  -53.49176025,  399.6446533 ,\n",
       "       -883.4948044 ,   95.36383057,  -64.30578613, -928.89044   ,\n",
       "       -127.8128052 ,  362.6905518 , -900.1123886 ,  159.4210815 ,\n",
       "       -226.4642334 , -907.0592537 ,  -31.52435303,  198.2196045 ,\n",
       "       -910.515995  ,   82.09344482])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## define dataset\n",
    "filename = 'walking.csv'\n",
    "filename_test = 'running.csv'\n",
    "\n",
    "# Read data\n",
    "headers = read_headers(filename)\n",
    "data = read_data(filename)\n",
    "\n",
    "# create train and test structures\n",
    "sData = som_data_struct(data.copy())\n",
    "sData_copy = copy.deepcopy(sData)\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data = read_data(filename_test)\n",
    "sTest = som_data_struct(test_data.copy())\n",
    "sTest['comp_names'] = headers\n",
    "sTest_copy = copy.deepcopy(sTest)\n",
    "\n",
    "## Normalize the Data\n",
    "plotdata = sData['data'].copy()\n",
    "sData_norm = som_normalize(sData_copy, 'var')\n",
    "\n",
    "plotdata_test = sTest['data'].copy()\n",
    "sTest_norm = som_normalize(sTest_copy, 'var')\n",
    "sTest_norm_copy = copy.deepcopy(sTest_norm)\n",
    "\n",
    "\n",
    "\n",
    "## Train the SOM\n",
    "sMap = som_make(sData_norm, *['lattice', 'shape', 'training'],**{'lattice':'hexa', 'shape':'sheet', 'training': 'long'})\n",
    "\n",
    "sMap['comp_names'] = headers\n",
    "\n",
    "\n",
    "\n",
    "## Find best-matching units\n",
    "Traj_train, Qerrs_train = som_bmus(sMap, sData_norm, 'all')\n",
    "Traj_train_coord = som_ind2sub(sMap, Traj_train[:,0])\n",
    "Traj_train_coord = np.concatenate((Traj_train_coord, Qerrs_train[:, [0]]), axis=1)\n",
    "line1 = np.concatenate((sMap['topol']['msize'], [0]))\n",
    "\n",
    "## SOM Testing\n",
    "Traj_test, Qerrs_test = som_bmus(sMap, sTest_norm_copy, 'all')\n",
    "Traj_test_coord = som_ind2sub(sMap, Traj_test[:,0])\n",
    "Traj_test_coord = np.concatenate((Traj_test_coord, Qerrs_test[:, [0]]), axis=1)\n",
    "\n",
    "\n",
    "## Denormalize the weight vectors\n",
    "M = som_denormalize(sMap['codebook'].copy(), *[sMap])\n",
    "\n",
    "Traj_train, Qerrs_train = som_bmus(M, plotdata.copy(), 'all')\n",
    "Traj_train_coord = som_ind2sub(sMap, Traj_train[:,0])\n",
    "Traj_train_coord = np.concatenate((Traj_train_coord, Qerrs_train[:, [0]]), axis=1)\n",
    "\n",
    "Traj_test, Qerrs_test = som_bmus(M, plotdata_test.copy(), 'all')\n",
    "Traj_test_coord = som_ind2sub(sMap, Traj_test[:,0])\n",
    "Traj_test_coord = np.concatenate((Traj_test_coord, Qerrs_test[:, [0]]), axis=1)\n",
    "\n",
    "breakpoint()\n",
    "\n",
    "## index all input vectors assigned to one neuron\n",
    "# find the lines that hit each neuron\n",
    "index = [[None for _ in range(line1[1])] for _ in range(line1[0])]\n",
    "\n",
    "# Iterate over t and q using nested loops\n",
    "for t in range(0, line1[1]):\n",
    "    for q in range(0, line1[0]):\n",
    "        index[q][t] = np.where((Traj_train_coord[:, 0] == q) & (Traj_train_coord[:, 1] == t))[0]\n",
    "\n",
    "\n",
    "# Compute average Frame number per neuron\n",
    "# Flatten index using list comprehension\n",
    "index_reQE = [item for sublist in index for item in sublist]\n",
    "# Number of frames (t)\n",
    "num_repeats = len(plotdata) // 101\n",
    "\n",
    "## Create a linearly spaced vector from 1 to 101\n",
    "frame = np.linspace(1, 101, 101)\n",
    "FRAMES = np.tile(frame, (num_repeats, 1)).flatten()\n",
    "FRAMES = FRAMES.reshape(-1, 1)\n",
    "\n",
    "FRAMES_SOM1 = np.zeros((len(M), 1))\n",
    "for r in range(len(M)):\n",
    "    FRAMES_SOM1[r, 0] = np.mean(FRAMES[index_reQE[r]])\n",
    "\n",
    "FRAMES_re = FRAMES_SOM1.reshape(line1[0], line1[1])\n",
    "\n",
    "extent = [0, FRAMES_re.shape[0], 0, FRAMES_re.shape[1]]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(FRAMES_re, aspect='auto', cmap='viridis', origin='lower', extent=extent)\n",
    "plt.colorbar(label='Gait cycle (%)')\n",
    "plt.xlabel('X Coordinate SOM')\n",
    "plt.ylabel('Y Coordinate SOM')\n",
    "plt.title('2D Heatmap of FRAMES together with the Trajectories')\n",
    "breakpoint()\n",
    "\n",
    "## EXPLORE THE MAP\n",
    "x_train = np.reshape(Traj_train_coord[:, 0], (101, -1), order='F')\n",
    "y_train = np.reshape(Traj_train_coord[:, 1], (101, -1), order='F') \n",
    "MEAN_train = np.column_stack((np.round(np.mean(x_train, axis=1)), np.round(np.mean(y_train, axis=1))))\n",
    "STD_train = np.column_stack((np.round(np.std(x_train, axis=1)), np.round(np.std(y_train, axis=1))))\n",
    "\n",
    "x_test = np.reshape(Traj_test_coord[:, 0], (101, -1), order='F')\n",
    "y_test = np.reshape(Traj_test_coord[:, 1], (101, -1), order='F')\n",
    "MEAN_test = np.column_stack((np.round(np.mean(x_test, axis=1)), np.round(np.mean(y_test, axis=1))))\n",
    "STD_test = np.column_stack((np.round(np.std(x_test, axis=1)), np.round(np.std(y_test, axis=1))))\n",
    "\n",
    "\n",
    "\n",
    "marker_sizes = np.ones(101) * 10  # Initialize all markers to size 10\n",
    "marker_sizes[0] = 20  # Make the first marker larger\n",
    "\n",
    "print(f\"MEAN_train range: X({MEAN_train[:, 0].min()} to {MEAN_train[:, 0].max()}), Y({MEAN_train[:, 1].min()} to {MEAN_train[:, 1].max()})\")\n",
    "print(f\"MEAN_test range: X({MEAN_test[:, 0].min()} to {MEAN_test[:, 0].max()}), Y({MEAN_test[:, 1].min()} to {MEAN_test[:, 1].max()})\")\n",
    "print(f\"FRAMES_re shape: {FRAMES_re.shape}\")\n",
    "\n",
    "# Define the extent based on the actual data ranges\n",
    "extent = [0, FRAMES_re.shape[0], 0, FRAMES_re.shape[1]]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(FRAMES_re, aspect='auto', cmap='viridis', origin='lower', extent=extent)\n",
    "plt.colorbar(label='Gait cycle (%)')\n",
    "plt.xlabel('X Coordinate SOM')\n",
    "plt.ylabel('Y Coordinate SOM')\n",
    "plt.title('2D Heatmap of FRAMES together with the Trajectories')\n",
    "\n",
    "# Plot MEAN_train and MEAN_test with error bars\n",
    "for i in range(101):\n",
    "    if i == 0:\n",
    "        plt.errorbar(MEAN_train[i, 0], MEAN_train[i, 1], xerr=STD_train[i, 0], yerr=STD_train[i, 1], fmt='none', ecolor='b', label='MEAN_train')\n",
    "        plt.errorbar(MEAN_test[i, 0], MEAN_test[i, 1], xerr=STD_test[i, 0], yerr=STD_test[i, 1], fmt='none', ecolor='r', label='MEAN_test')\n",
    "        plt.plot(MEAN_train[i, 0], MEAN_train[i, 1], 'bo', markersize=marker_sizes[i])\n",
    "        plt.plot(MEAN_test[i, 0], MEAN_test[i, 1], 'ro', markersize=marker_sizes[i])\n",
    "    else:\n",
    "        plt.errorbar(MEAN_train[i, 0], MEAN_train[i, 1], xerr=STD_train[i, 0], yerr=STD_train[i, 1], fmt='none', ecolor='b')\n",
    "        plt.errorbar(MEAN_test[i, 0], MEAN_test[i, 1], xerr=STD_test[i, 0], yerr=STD_test[i, 1], fmt='none', ecolor='r')\n",
    "        plt.plot(MEAN_train[i, 0], MEAN_train[i, 1], 'bo', markersize=marker_sizes[i])\n",
    "        plt.plot(MEAN_test[i, 0], MEAN_test[i, 1], 'ro', markersize=marker_sizes[i])\n",
    "\n",
    "# Set aspect ratio to be equal\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "breakpoint()\n",
    "\n",
    "## MOVEMENT DEVIATION PROFILE\n",
    "# here the aim is to find the difference in Quantization Errors of the train and the test set\n",
    "# relative to the SOM. These errors are then compared and illustrated into the so-called Movement \n",
    "# Deviation Profile (MDP)\n",
    "\n",
    "# Reshape the first column of Traj_train\n",
    "error_train = np.reshape(Traj_train_coord[:, 2], (101, -1), order='F')\n",
    "MEAN_error_train = np.mean(error_train,axis=1)\n",
    "STD_error_train = np.std(error_train, axis=1)\n",
    "\n",
    "\n",
    "error_test = np.reshape(Traj_test_coord[:, 2], (101, -1), order='F')\n",
    "MEAN_error_test = np.mean(error_test,axis=1)\n",
    "STD_error_test = np.std(error_test, axis=1)\n",
    "\n",
    "x = np.arange(1, 102)\n",
    "y = STD_error_train\n",
    "# Create the plot\n",
    "plt.figure()\n",
    "p1, = plt.plot(x, MEAN_error_train, 'k', linewidth=4, label='train Mean')\n",
    "plt.fill_between(x, MEAN_error_train - y , MEAN_error_train + y, color=[0.6, 0.7, 0.8], alpha=0.2)\n",
    "p2, = plt.plot(x, MEAN_error_test, 'r', label='test_MEAN')\n",
    "\n",
    "plt.xlim([1, 101])\n",
    "plt.xlabel('Gait Cycle (%)')\n",
    "plt.ylabel('Quantization Error')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "breakpoint()\n",
    "\n",
    "### CLUSTER the data based on the bmus\n",
    "data1 = np.reshape(Traj_train_coord[:,0:3],(684, 101,3))\n",
    "data2 = np.reshape(Traj_test_coord[:,0:3],(168, 101,3))\n",
    "\n",
    "# Combine data along the first axis (vertical concatenation)\n",
    "combined_data = np.concatenate((data1, data2), axis=0)\n",
    "\n",
    "# Reshape data for clustering\n",
    "flattened_data = combined_data.reshape(combined_data.shape[0], -1)\n",
    "\n",
    "# Initialize K-means model\n",
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "\n",
    "# Fit K-means model to flattened data\n",
    "kmeans.fit(flattened_data)\n",
    "\n",
    "# Get cluster labels\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "# Separate indices of data1 and data2\n",
    "num_data1 = data1.shape[0]\n",
    "num_data2 = data2.shape[0]\n",
    "\n",
    "# Create arrays to store indices of data1 and data2 in each cluster\n",
    "data1_clusters = np.zeros(num_data1, dtype=int)  # Array to store cluster labels for data1\n",
    "data2_clusters = np.zeros(num_data2, dtype=int)  # Array to store cluster labels for data2\n",
    "\n",
    "# Assign cluster labels to data1\n",
    "data1_clusters[cluster_labels[:num_data1] == 0] = 1  # Assign cluster 1 to trajectories in data1\n",
    "data1_clusters[cluster_labels[:num_data1] == 1] = 2  # Assign cluster 2 to trajectories in data1\n",
    "\n",
    "# Assign cluster labels to data2\n",
    "data2_clusters[cluster_labels[num_data1:] == 0] = 1  # Assign cluster 1 to trajectories in data2\n",
    "data2_clusters[cluster_labels[num_data1:] == 1] = 2  # Assign cluster 2 to trajectories in data2\n",
    "\n",
    "# Combine the cluster labels into a single array\n",
    "cluster_assignment = np.concatenate((data1_clusters, data2_clusters))\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot data1 trajectories\n",
    "for i in range(num_data1):\n",
    "    if cluster_assignment[i] == 1:\n",
    "        ax.plot(data1[i, :, 0], data1[i, :, 1], data1[i, :, 2], color='blue', alpha=0.5, label='Cluster 1' if i == 0 else '')\n",
    "    elif cluster_assignment[i] == 2:\n",
    "        ax.plot(data1[i, :, 0], data1[i, :, 1], data1[i, :, 2], color='red', alpha=0.5, label='Cluster 2' if i == 0 else '')\n",
    "\n",
    "# Plot data2 trajectories\n",
    "for i in range(num_data2):\n",
    "    index = i + num_data1\n",
    "    if cluster_assignment[index] == 1:\n",
    "        ax.plot(data2[i, :, 0], data2[i, :, 1], data2[i, :, 2], color='red', alpha=0.5, label='Cluster 2' if i == 0 else '')\n",
    "    elif cluster_assignment[index] == 2:\n",
    "        ax.plot(data2[i, :, 0], data2[i, :, 1], data2[i, :, 2], color='red', alpha=0.5, label='Cluster 2' if i == 0 else '')\n",
    "\n",
    "plt.title('3D Clustered Trajectories')\n",
    "ax.set_xlabel('X Coordinate')\n",
    "ax.set_ylabel('Y Coordinate')\n",
    "ax.set_zlabel('Quantization Error')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "unique_labels = dict(zip(labels, handles))\n",
    "ax.legend(unique_labels.values(), unique_labels.keys())\n",
    "plt.show()\n",
    "\n",
    "# Print the cluster assignments (just for demonstration)\n",
    "print(\"Cluster assignments:\")\n",
    "for i in range(len(cluster_assignment)):\n",
    "    if i < num_data1:\n",
    "        print(f\"Data1 slice {i} is in Cluster {cluster_assignment[i]}\")\n",
    "    else:\n",
    "        print(f\"Data2 slice {i - num_data1} is in Cluster {cluster_assignment[i]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
