{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Print the current working directory\n",
    "cwd = os.getcwd()\n",
    "if cwd.endswith('SOM_package'):\n",
    "    print('Current working directory is already set to the package directory')\n",
    "else:\n",
    "    os.chdir(cwd + '/SOM_package')\n",
    "from som_data_struct import som_data_struct\n",
    "from som_normalize import som_normalize\n",
    "from som_make import som_make\n",
    "from som_bmus import som_bmus\n",
    "from som_ind2sub import som_ind2sub\n",
    "from som_denormalize import som_denormalize\n",
    "from reader import *\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import copy\n",
    "from sklearn.cluster import KMeans\n",
    "os.chdir('../')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_start_end_indices(labels_dataframe, ID):\n",
    "        start_test = labels_dataframe.groupby('Participant').head(1).index.tolist()\n",
    "        end_test = start_test[1:] + [len(labels_dataframe)]\n",
    "        return start_test, end_test\n",
    "\n",
    "def correct_end_position(end_test):\n",
    "    end_test_c = [x-1 for x in end_test]\n",
    "    end_test_c[-1] =end_test_c[-1]+1\n",
    "    return end_test_c\n",
    "\n",
    "# Read the data\n",
    "### Placeholder datafunction\n",
    "data_path = ['ME.data', 'LC.data', 'Controls.data']\n",
    "for data_p in data_path:\n",
    "    data_set = pd.read_csv(data_p, delimiter=' ', na_values='NaN', header=None, skiprows=2)\n",
    "    \n",
    "    # Extract headers\n",
    "    header_start = data_set.shape[1] - 2\n",
    "    headers = read_headers(data_p)\n",
    "    headers = [header.strip() for header in headers]\n",
    "    \n",
    "    # Define labels and component names\n",
    "    label_names = headers[header_start:]\n",
    "    compnames = headers[0:header_start]\n",
    "    compnames = np.array(compnames)\n",
    "    \n",
    "    # Extract labels and data\n",
    "    labels = data_set.iloc[:, header_start:]\n",
    "    labels = labels.to_numpy()\n",
    "    data = data_set.iloc[:, 0:header_start]\n",
    "    data = data.to_numpy()\n",
    "    \n",
    "    # Create the structured data dictionary\n",
    "    sData = som_data_struct(data.copy())\n",
    "    sData['label_names'] = label_names\n",
    "    sData['comp_names'] = compnames\n",
    "    sData['labels'] = labels\n",
    "    sData_copy = copy.deepcopy(sData)\n",
    "    dataframe_labels = pd.DataFrame(sData['labels'])\n",
    "    dataframe_labels.columns = sData['label_names']\n",
    "\n",
    "    # Remove Phase NONE and get start and end indices\n",
    "    ID = dataframe_labels.iloc[:,0].unique()\n",
    "    phase = dataframe_labels.iloc[:,1].unique()\n",
    "    start_test, end_test = get_start_end_indices(dataframe_labels, ID)\n",
    "    temp_labels = dataframe_labels[dataframe_labels['Phase'] != 'NONE']\n",
    "    sData['labels'] = temp_labels.to_numpy()\n",
    "    # MAKING BREATH TIMES\n",
    "    MIN = []\n",
    "    MAX = []\n",
    "    breath_time = []\n",
    "    sData_data_df = pd.DataFrame(sData['data'])\n",
    "    sData_data_df.columns = sData['comp_names']\n",
    "    for i in range(len(ID)):\n",
    "        start = start_test[i]\n",
    "        end = end_test[i]\n",
    "        bt = np.diff(sData_data_df.iloc[start:end, 0].to_numpy(), prepend=0)\n",
    "        #bt[bt < -100] = np.nan\n",
    "        breath_time.append(bt)\n",
    "        MIN.append(np.nanmin(bt))\n",
    "        MAX.append(np.nanmax(bt))        \n",
    "    breath_data = sData_data_df.iloc[:,0]\n",
    "    sData_data_df.iloc[:,0] = pd.Series(np.concatenate(breath_time))\n",
    "    end_test_c = correct_end_position(end_test) \n",
    "    # FIND TRIAL PHASES FOR EACH PARTICIPANT\n",
    "    start_exercise = []\n",
    "    end_exercise = []\n",
    "    for i in range(len(ID)):\n",
    "        ip = temp_labels[start_test[i]:end_test_c[i]].groupby('Phase').head(1)\n",
    "        start_exercise.append(ip[ip['Phase'] == 'EXERCISE'].index[0])\n",
    "        end_exercise.append((temp_labels[start_test[i]:end_test_c[i]]['Phase'] == 'EXERCISE').index[-1])\n",
    "    \n",
    "    # CREATE A DICT FOR EXERCISE PART OF TRIALS\n",
    "    exercise_cell = [sData_data_df.iloc[start_exercise[i]:end_exercise[i]].to_numpy() for i in range(len(ID))]\n",
    "    labels_exercise = [np.repeat(ID[i], len(exercise_cell[i])) for i in range(len(ID))]\n",
    "    allLabels = np.concatenate(labels_exercise)\n",
    "\n",
    "    sData_exercise = som_data_struct(np.vstack(exercise_cell))\n",
    "    sData_exercise['label_names'] = [label_names[0]]\n",
    "    sData_exercise['comp_names'] = compnames\n",
    "    sData_exercise['labels'] = allLabels \n",
    "    dataframe_labels_exercise = pd.DataFrame(sData_exercise['labels'])\n",
    "    dataframe_labels_exercise.columns = [sData_exercise['label_names'][0]]\n",
    "    start_test_exercise, end_test_exercise = get_start_end_indices(dataframe_labels_exercise, ID)\n",
    "    breath_nr = np.concatenate([np.arange(1, end_test_exercise[i] - start_test_exercise[i] + 2) for i in range(len(ID))])\n",
    "\n",
    "\n",
    "    if data_p == 'ME.data':\n",
    "        sData_ME = sData_exercise.copy()\n",
    "        sData_ME_copy = copy.deepcopy(sData_ME)\n",
    "        plotdata_ME = sData_ME['data'].copy\n",
    "        sData_ME_norm = som_normalize(sData_ME, 'var')\n",
    "        sData_ME_norm_copy = copy.deepcopy(sData_ME_norm)\n",
    "    elif data_p == 'LC.data':\n",
    "        sData_LC = sData_exercise.copy()\n",
    "        sData_LC_copy = copy.deepcopy(sData_LC)\n",
    "        plotdata_LC = sData_LC['data'].copy\n",
    "        sData_LC_norm = som_normalize(sData_LC, 'var')\n",
    "        sData_LC_norm_copy = copy.deepcopy(sData_LC_norm)\n",
    "    elif data_p == 'Controls.data':\n",
    "        sData_controls = sData_exercise.copy()\n",
    "        sData_controls_copy = copy.deepcopy(sData_controls)\n",
    "        plotdata_controls = sData_controls['data'].copy\n",
    "        sData_controls_norm = som_normalize(sData_controls, 'var')\n",
    "        sData_controls_norm_copy = copy.deepcopy(sData_controls_norm)\n",
    "    else:\n",
    "        print('Error in data reading: Weird data path')\n",
    "#sMap = som_make(sData_controls_norm, *['lattice', 'shape', 'training'],**{'lattice':'hexa', 'shape':'sheet', 'training': 'long'})  \n",
    "#sMap['comp_names'] = headers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>Power</th>\n",
       "      <th>HR</th>\n",
       "      <th>VE</th>\n",
       "      <th>VO2</th>\n",
       "      <th>VCO2</th>\n",
       "      <th>PetCO2</th>\n",
       "      <th>PetO2</th>\n",
       "      <th>VO2/Kg</th>\n",
       "      <th>VE/VO2</th>\n",
       "      <th>VE/VCO2</th>\n",
       "      <th>RQ</th>\n",
       "      <th>VT</th>\n",
       "      <th>Rf</th>\n",
       "      <th>Ti</th>\n",
       "      <th>Te</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.062</td>\n",
       "      <td>324.304065</td>\n",
       "      <td>234.075281</td>\n",
       "      <td>33.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>4.36</td>\n",
       "      <td>22.2</td>\n",
       "      <td>30.7</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.653</td>\n",
       "      <td>12.35</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.640</td>\n",
       "      <td>342.544765</td>\n",
       "      <td>239.146688</td>\n",
       "      <td>35.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>4.61</td>\n",
       "      <td>20.4</td>\n",
       "      <td>29.3</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.834</td>\n",
       "      <td>9.16</td>\n",
       "      <td>1.96</td>\n",
       "      <td>4.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.733</td>\n",
       "      <td>368.639749</td>\n",
       "      <td>255.788145</td>\n",
       "      <td>32.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>4.96</td>\n",
       "      <td>20.9</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.588</td>\n",
       "      <td>14.85</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.354</td>\n",
       "      <td>356.479196</td>\n",
       "      <td>249.670125</td>\n",
       "      <td>32.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>4.80</td>\n",
       "      <td>20.6</td>\n",
       "      <td>29.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.582</td>\n",
       "      <td>14.35</td>\n",
       "      <td>1.51</td>\n",
       "      <td>2.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.964</td>\n",
       "      <td>351.126102</td>\n",
       "      <td>247.138020</td>\n",
       "      <td>34.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>4.73</td>\n",
       "      <td>20.3</td>\n",
       "      <td>28.9</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.673</td>\n",
       "      <td>11.83</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9636</th>\n",
       "      <td>3.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>45.829</td>\n",
       "      <td>1079.996562</td>\n",
       "      <td>1205.360978</td>\n",
       "      <td>29.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>14.34</td>\n",
       "      <td>41.4</td>\n",
       "      <td>37.1</td>\n",
       "      <td>1.12</td>\n",
       "      <td>2.765</td>\n",
       "      <td>16.57</td>\n",
       "      <td>1.15</td>\n",
       "      <td>2.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9637</th>\n",
       "      <td>5.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>22.694</td>\n",
       "      <td>498.584751</td>\n",
       "      <td>542.316133</td>\n",
       "      <td>32.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>6.62</td>\n",
       "      <td>43.9</td>\n",
       "      <td>40.4</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.963</td>\n",
       "      <td>11.56</td>\n",
       "      <td>1.24</td>\n",
       "      <td>3.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9638</th>\n",
       "      <td>3.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>60.412</td>\n",
       "      <td>1567.376216</td>\n",
       "      <td>1623.980397</td>\n",
       "      <td>30.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>20.82</td>\n",
       "      <td>37.6</td>\n",
       "      <td>36.3</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.930</td>\n",
       "      <td>20.62</td>\n",
       "      <td>1.21</td>\n",
       "      <td>1.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9639</th>\n",
       "      <td>3.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>55.416</td>\n",
       "      <td>1301.385957</td>\n",
       "      <td>1398.073963</td>\n",
       "      <td>28.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>17.28</td>\n",
       "      <td>41.5</td>\n",
       "      <td>38.7</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2.817</td>\n",
       "      <td>19.67</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9640</th>\n",
       "      <td>4.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>43.927</td>\n",
       "      <td>937.605237</td>\n",
       "      <td>1030.617283</td>\n",
       "      <td>26.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>12.45</td>\n",
       "      <td>45.4</td>\n",
       "      <td>41.3</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2.211</td>\n",
       "      <td>19.87</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9641 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        t  Power     HR      VE          VO2         VCO2  PetCO2  PetO2  \\\n",
       "0     5.0    0.0    NaN   8.062   324.304065   234.075281    33.0  108.0   \n",
       "1     7.0    0.0    NaN   7.640   342.544765   239.146688    35.0  103.0   \n",
       "2     3.0    0.0    NaN   8.733   368.639749   255.788145    32.0  108.0   \n",
       "3     5.0    0.0    NaN   8.354   356.479196   249.670125    32.0  107.0   \n",
       "4     5.0    0.0    NaN   7.964   351.126102   247.138020    34.0  105.0   \n",
       "...   ...    ...    ...     ...          ...          ...     ...    ...   \n",
       "9636  3.0  360.0  122.0  45.829  1079.996562  1205.360978    29.0  121.0   \n",
       "9637  5.0  365.0  122.0  22.694   498.584751   542.316133    32.0  115.0   \n",
       "9638  3.0  365.0  124.0  60.412  1567.376216  1623.980397    30.0  118.0   \n",
       "9639  3.0  365.0  122.0  55.416  1301.385957  1398.073963    28.0  120.0   \n",
       "9640  4.0  370.0  122.0  43.927   937.605237  1030.617283    26.0  123.0   \n",
       "\n",
       "      VO2/Kg  VE/VO2  VE/VCO2    RQ     VT     Rf    Ti    Te  \n",
       "0       4.36    22.2     30.7  0.72  0.653  12.35  1.87  2.99  \n",
       "1       4.61    20.4     29.3  0.70  0.834   9.16  1.96  4.59  \n",
       "2       4.96    20.9     30.1  0.69  0.588  14.85  1.80  2.24  \n",
       "3       4.80    20.6     29.4  0.70  0.582  14.35  1.51  2.67  \n",
       "4       4.73    20.3     28.9  0.70  0.673  11.83  2.05  3.02  \n",
       "...      ...     ...      ...   ...    ...    ...   ...   ...  \n",
       "9636   14.34    41.4     37.1  1.12  2.765  16.57  1.15  2.47  \n",
       "9637    6.62    43.9     40.4  1.09  1.963  11.56  1.24  3.95  \n",
       "9638   20.82    37.6     36.3  1.04  2.930  20.62  1.21  1.70  \n",
       "9639   17.28    41.5     38.7  1.07  2.817  19.67  1.18  1.87  \n",
       "9640   12.45    45.4     41.3  1.10  2.211  19.87  1.39  1.63  \n",
       "\n",
       "[9641 rows x 16 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sData_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2     61\n",
       "3      0\n",
       "4      0\n",
       "5      0\n",
       "6      0\n",
       "7      0\n",
       "8      0\n",
       "9      0\n",
       "10     0\n",
       "11     0\n",
       "12     0\n",
       "13     0\n",
       "14     0\n",
       "15     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sData_ME_norm['data']).isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct breath number index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # CHANGES IN WATTS\n",
    "    # individualize\n",
    "    data_exercise = pd.DataFrame(sData_exercise['data'])\n",
    "    dif_data = [np.diff(data_exercise.iloc[start_test_exercise[i]:end_test_exercise[i], 1]) for i in range(len(ID))]\n",
    "    \n",
    "    # NORMALIZE DATA\n",
    "    differences = []\n",
    "    max_diff = 0\n",
    "    trial_length1 = dataframe_labels_exercise.groupby('Participant').head(1).index.tolist()\n",
    "    for i in range(len(trial_length1)):\n",
    "        if i < len(trial_length1)-1:\n",
    "            diff = trial_length1[i+1] - trial_length1[i]\n",
    "            differences.append(diff)\n",
    "        if i == len(trial_length1)-1:\n",
    "            diff = len(dataframe_labels_exercise) - trial_length1[i]\n",
    "            differences.append(diff)\n",
    "        if diff > max_diff:\n",
    "            max_diff = diff\n",
    "            max_diff_index = i\n",
    "\n",
    "    #Normalised based on Duration of trial, Because starting resistance differed between trials  \n",
    "    diff_normalised = [max_diff/difference for difference in differences]\n",
    "    data_normalized = [data_exercise.iloc[start_test_exercise[i]:end_test_exercise[i]].apply(lambda x: x * diff_normalised[i], axis=1).to_numpy() for i in range(len(ID))]\n",
    "    data_cell = []\n",
    "    for i in range(len(differences)):\n",
    "        trial_matrix = np.full((max_diff, data_exercise.shape[1]), np.nan)\n",
    "        data_cell.append(0)\n",
    "        trial_matrix[:differences[i], :data_exercise.shape[1]] = data_normalized[i]\n",
    "        data_cell[i] = trial_matrix\n",
    "    data_cell_v = np.vstack(data_cell)\n",
    "    data_cell_df = pd.DataFrame(data_cell_v)\n",
    "    data_cell_df.columns = sData_exercise['comp_names']\n",
    "    sData_normalized = som_data_struct(data_cell_v)\n",
    "    sData_normalized['label_names'] = [label_names[0]]\n",
    "    sData_normalized['comp_names'] = compnames\n",
    "    sData_normalized['labels'] = allLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "WATTS = data_cell_df['Power']\n",
    "data_cell_df.drop(columns=['t', 'Power'], inplace=True)\n",
    "if data_p == 'LC.data':\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEPARATE TARGET VARIABLE FROM DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_path == 'LC.data':\n",
    "    datapoints_LC = len(data_normalized['labels'])\n",
    "    LC_data = data_normalized['data'].copy()\n",
    "    LC_labels = data_normalized['labels'].copy()\n",
    "    LC_dict = {\"type\":data_normalized[\"type\"], \"data\": LC_data, \"labels\": LC_labels, \"comp_names\": data_normalized[\"comp_names\"], \"comp_norm\": data_normalized[\"comp_norm\"], \"label_names\": data_normalized[\"label_names\"]}\n",
    "    LC_dict['labels'] = pd.DataFrame(LC_dict['labels'], columns = ['participant'])\n",
    "    LC_dict['data'].columns = compnames[2:]\n",
    "\n",
    "if data_path == 'Controls.data':\n",
    "    datapoints_controls = len(data_normalized['labels'])\n",
    "    Control_data = data_normalized['data'].copy()\n",
    "    Control_labels = data_normalized['labels'].copy()\n",
    "    Control_dict = {\"type\":data_normalized[\"type\"], \"data\": Control_data, \"labels\": Control_labels, \"comp_names\": data_normalized[\"comp_names\"], \"comp_norm\": data_normalized[\"comp_norm\"], \"label_names\": data_normalized[\"label_names\"]}\n",
    "    Control_dict['labels'] = pd.DataFrame(Control_dict['labels'], columns = ['participant'])\n",
    "    Control_dict['data'].columns = compnames[2:]\n",
    "\n",
    "if data_path == 'ME.data':\n",
    "    datapoints_me = len(data_normalized['labels'])\n",
    "    ME_data = data_normalized['data'].copy()\n",
    "    ME_labels = data_normalized['labels'].copy()\n",
    "    ME_dict = {\"type\":data_normalized[\"type\"], \"data\": ME_data, \"labels\": ME_labels, \"comp_names\": data_normalized[\"comp_names\"], \"comp_norm\": data_normalized[\"comp_norm\"], \"label_names\": data_normalized[\"label_names\"]}\n",
    "    ME_dict['labels'] = pd.DataFrame(ME_dict['labels'], columns = ['participant'])\n",
    "    ME_dict['data'].columns = compnames[2:]\n",
    "\n",
    "# Find start and end of each trial from breath time\n",
    "start_test_n, end_test_n = get_start_end_indices(data_normalized, ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explory(data_dict, column):\n",
    "    plt.figure(1)\n",
    "    plt.plot(data_dict['data'][column])\n",
    "    plt.title(column)\n",
    "    plt.show()\n",
    "    plt.figure(2)\n",
    "    plt.hist(data_dict['data'][column])\n",
    "    plt.title(column)\n",
    "    plt.show()\n",
    "    plt.figure(3)\n",
    "    plt.boxplot(data_dict['data'][column])\n",
    "    plt.title(column)\n",
    "    plt.show()\n",
    "    print(data_dict['data'][column].describe())\n",
    "    print(data_dict['data'][column].isna().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
